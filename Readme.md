# Towards Video-LLM Driven Workflow for Behavioral Segmentation and Scoring in Mice Performing a Skilled Water Reaching Task: An Evaluation of Recent LLM Models 


This repository contains scripts for processing and analyzing videos using large vision models (LLMs), as well as tools for plotting and visualizing the results for the paper:
Towards Video-LLM Driven Workflow for Behavioral Segmentation and Scoring in Mice Performing a Skilled Water Reaching Task: An Evaluation of Recent LLM Models. 

The primary components include scripts for local processing with **QwenVL3** and **VideoLLaMA3**, and a sample notebook for processing with the **Google Gemini API**.

## üìÇ Key Components

* **Video Processing Notebooks/Scripts:**
    * `wr_evluate_gemini.ipynb`: A sample Jupyter Notebook demonstrating how to upload and process videos using the Google Gemini Pro API.
    * `wr_evaluate_qwen.py`: A script for processing videos locally using the **QwenVL3** model.
    * `wr_evaluate_videollama.py`: A script for processing videos locally using the **VideoLLaMA3** model. *(Please update this filename if incorrect)*.
* **Analysis & Plotting:**
    * Contains various scripts for analyzing and plotting the results generated by the models.
    * Includes schemes for generating structured output (e.g., JSON) from the video analysis.

## üõ†Ô∏è Environment Setup

To run the local processing scripts, you must set up their respective environments first.

1.  **QwenVL3 (for `wr_evaluate_qwen.py`)**
    * Follow the official setup instructions at:
        [https://github.com/QwenLM/Qwen3-VL/](https://github.com/QwenLM/Qwen3-VL/)

2.  **VideoLLaMA3 (for `wr_evaluate_videollama.py`)**
    * Follow the official setup instructions at:
        [https://github.com/DAMO-NLP-SG/VideoLLaMA3](https://github.com/DAMO-NLP-SG/VideoLLaMA3)

3.  **Gemini API (for `wr_evluate_gemini`)**
    * You will need a Google AI Studio API key and the `google-generativeai` Python library.
    * Install the library via pip:
        ```bash
        pip install google-generativeai
        ```

## üöÄ Usage

### 1. Gemini Pro (Notebook)
1.  Open `Gemini.ipynb` in a Jupyter environment (like VS Code or Jupyter Lab).
2.  Add your Google API key where indicated.
3.  Follow the steps in the notebook to upload and process your video files.

### 2. Local Models (Scripts)
After setting up the required environments:

* **Run QwenVL3:**
    ```bash
    # Make sure the QwenVL3 environment is activated
    python wr_evaluate_qwen.py --video_path /path/to/your/video.mp4
    ```

* **Run VideoLLaMA3:**
    ```bash
    # Make sure the VideoLLaMA3 environment is activated
    python wr_evaluate_videollama.py --video_path /path/to/your/video.mp4
    ```

*(Note: Update the command-line arguments above if your scripts use different flags.)*