{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "751b92be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    balanced_accuracy_score, f1_score  # <<< NEW >>>\n",
    ")\n",
    "from utils import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b4f6161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from 'hand_scored' directory...\n",
      "Loading files from 'gemini_predictions' directory...\n"
     ]
    }
   ],
   "source": [
    "path1 = '/mnt/teams/TM_Lab/Tony/wr_new/data_used/tta_gcamp8s/hand_scored'\n",
    "path2 = '/mnt/teams/TM_Lab/Tony/wr_new/data_used/tta_gcamp8s/gemini_predictions_full_sys'\n",
    "\n",
    "# --- Create the first dictionary for the 'hand_scored' files ---\n",
    "print(\"Loading files from 'hand_scored' directory...\")\n",
    "hand_scored_data = {} # Initialize an empty dictionary\n",
    "# Loop through every file in the first directory\n",
    "for filename in os.listdir(path1):\n",
    "    # We only care about CSV files\n",
    "    if filename.endswith('.csv'):\n",
    "        # Create the full path to the file\n",
    "        file_path = os.path.join(path1, filename)\n",
    "        try:\n",
    "            # Use the filename as the key and the loaded CSV data (a DataFrame) as the value\n",
    "            hand_scored_data[filename] = pd.read_csv(file_path)\n",
    "            #print(f\"  - Loaded: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - FAILED to load {filename}. Error: {e}\")\n",
    "print(\"Loading files from 'gemini_predictions' directory...\")\n",
    "gemini_predictions_data = {} # Initialize the second empty dictionary\n",
    "\n",
    "# Loop through every file in the second directory\n",
    "for filename in os.listdir(path2):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(path2, filename)\n",
    "        try:\n",
    "            gemini_predictions_data[filename] = pd.read_csv(file_path)\n",
    "            #print(f\"  - Loaded: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  - FAILED to load {filename}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ee656e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 'hand_scored_data' to simplify outcomes...\n",
      "Simplification of all hand-scored data is complete.\n",
      "\n",
      "Simplification of all hand-scored data is complete.\n",
      "\n",
      "Processing 'hand_scored_data' to simplify outcomes...\n",
      "Simplification of all hand-scored data is complete.\n",
      "\n",
      "Simplification of all hand-scored data is complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Simplify ALL Hand-Scored CSVs ---\n",
    "\n",
    "print(\"Processing 'hand_scored_data' to simplify outcomes...\")\n",
    "hand_scored_mapping = {\n",
    "    'ps': 's',\n",
    "    'rnd': 'f'\n",
    "}\n",
    "for filename, df in hand_scored_data.items():\n",
    "    if 'outcome' in df.columns:\n",
    "        df['outcome'] = df['outcome'].replace(hand_scored_mapping)\n",
    "    else:\n",
    "        print(f\"  - WARNING: 'outcome' column not found in {filename}\")\n",
    "print(\"Simplification of all hand-scored data is complete.\\n\")\n",
    "\n",
    "for filename, df in gemini_predictions_data.items():\n",
    "    if 'outcome_classification' in df.columns:\n",
    "        df['outcome_classification'] = df['outcome_classification'].replace(hand_scored_mapping)\n",
    "    else:\n",
    "        print(f\"  - WARNING: 'outcome' column not found in {filename}\")\n",
    "print(\"Simplification of all hand-scored data is complete.\\n\")\n",
    "\n",
    "# --- 3. Simplify ALL Gemini CSVs ---\n",
    "'''\n",
    "print(\"Processing 'gemini_predictions_data' based on 'percentage_consumed'...\")\n",
    "for filename, df in gemini_predictions_data.items():\n",
    "    if 'percentage_consumed' in df.columns and 'outcome_classification' in df.columns:\n",
    "        df['outcome_classification'] = 'f'\n",
    "        df.loc[df['percentage_consumed'] >= 30, 'outcome_classification'] = 's'\n",
    "        df.loc[df['percentage_consumed'].isna(), 'outcome_classification'] = np.nan\n",
    "    else:\n",
    "        print(f\"  - WARNING: Required columns not found in {filename}\")\n",
    "print(\"Simplification of all Gemini data is complete.\")\n",
    "'''\n",
    "print(\"Processing 'hand_scored_data' to simplify outcomes...\")\n",
    "hand_scored_mapping = {\n",
    "    'ps': 's',\n",
    "    'rnd': 'f'\n",
    "}\n",
    "for filename, df in hand_scored_data.items():\n",
    "    if 'outcome' in df.columns:\n",
    "        df['outcome'] = df['outcome'].replace(hand_scored_mapping)\n",
    "    else:\n",
    "        print(f\"  - WARNING: 'outcome' column not found in {filename}\")\n",
    "print(\"Simplification of all hand-scored data is complete.\\n\")\n",
    "\n",
    "for filename, df in gemini_predictions_data.items():\n",
    "    if 'outcome' in df.columns:\n",
    "        df['outcome'] = df['outcome'].replace(hand_scored_mapping)\n",
    "    else:\n",
    "        print(f\"  - WARNING: 'outcome' column not found in {filename}\")\n",
    "print(\"Simplification of all hand-scored data is complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12ef775e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting batch processing of 29 sessions...\n",
      "\n",
      "\n",
      "[1/29] Processing K_R3_2025-02-04_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: K_R3_2025-02-04_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 41 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[2/29] Processing FJ_R3_2024-07-15_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_R3_2024-07-15_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 114 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[3/29] Processing AZ_R2_2024-12-14_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: AZ_R2_2024-12-14_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 77 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[4/29] Processing K_R3_2025-02-21_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: K_R3_2025-02-21_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 37 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[5/29] Processing FJ_L3_2024-07-15_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_L3_2024-07-15_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 71 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[6/29] Processing FU_R2_2024-06-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FU_R2_2024-06-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 52 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[7/29] Processing K_R2_2025-02-04_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: K_R2_2025-02-04_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 38 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[8/29] Processing AZ_L3_2024-12-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: AZ_L3_2024-12-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 65 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[9/29] Processing FS_L2_2024-06-28_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FS_L2_2024-06-28_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 34 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[10/29] Processing FS_R2_2024-06-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FS_R2_2024-06-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 20 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[11/29] Processing FJ_R3_2024-07-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_R3_2024-07-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 31 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[12/29] Processing AZ_R2_2024-11-22_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: AZ_R2_2024-11-22_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 46 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[13/29] Processing FJ_R3_2024-06-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_R3_2024-06-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 78 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[14/29] Processing AZ_L3_2024-11-22_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: AZ_L3_2024-11-22_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 70 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[15/29] Processing FJ_R2_2024-07-15_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_R2_2024-07-15_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 82 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[16/29] Processing FU_R2_2024-07-18_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FU_R2_2024-07-18_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 65 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[17/29] Processing K_R3_2025-01-13_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: K_R3_2025-01-13_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 43 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[18/29] Processing K_R2_2025-01-14_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: K_R2_2025-01-14_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 46 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[19/29] Processing AZ_L3_2024-12-16_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: AZ_L3_2024-12-16_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 94 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[20/29] Processing FJ_R2_2024-06-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_R2_2024-06-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 34 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[21/29] Processing FJ_L3_2024-06-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_L3_2024-06-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 60 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[22/29] Processing FJ_L2_2024-07-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_L2_2024-07-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 74 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[23/29] Processing AZ_R2_2024-12-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: AZ_R2_2024-12-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 92 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[24/29] Processing FJ_R2_2024-07-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_R2_2024-07-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 92 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[25/29] Processing K_R3_2025-01-14_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: K_R3_2025-01-14_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 83 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[26/29] Processing FJ_L2_2024-06-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_L2_2024-06-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 74 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[27/29] Processing FS_L2_2024-07-31_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FS_L2_2024-07-31_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 79 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[28/29] Processing FJ_L2_2024-07-15_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_L2_2024-07-15_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 91 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "[29/29] Processing FJ_L3_2024-07-29_1.csv...\n",
      "\n",
      "======================================================================\n",
      "PROCESSING: FJ_L3_2024-07-29_1.csv\n",
      "======================================================================\n",
      "\n",
      "[Step 1] Validating and merging data...\n",
      "  Total merged rows: 120\n",
      "  Removing 55 rows with invalid hand-scored values\n",
      "  Removing 120 rows with invalid Gemini predictions\n",
      "  ‚ùå No valid data after cleaning\n",
      "\n",
      "======================================================================\n",
      "üìä BATCH PROCESSING SUMMARY\n",
      "======================================================================\n",
      "‚úÖ Successful: 0/29\n",
      "‚ùå Failed: 29/29\n",
      "‚ö†Ô∏è  With class mismatches: 0/0\n",
      "\n",
      "‚ùå Failed sessions:\n",
      "   - K_R3_2025-02-04_1.csv: Processing failed\n",
      "   - FJ_R3_2024-07-15_1.csv: Processing failed\n",
      "   - AZ_R2_2024-12-14_1.csv: Processing failed\n",
      "   - K_R3_2025-02-21_1.csv: Processing failed\n",
      "   - FJ_L3_2024-07-15_1.csv: Processing failed\n",
      "   - FU_R2_2024-06-29_1.csv: Processing failed\n",
      "   - K_R2_2025-02-04_1.csv: Processing failed\n",
      "   - AZ_L3_2024-12-29_1.csv: Processing failed\n",
      "   - FS_L2_2024-06-28_1.csv: Processing failed\n",
      "   - FS_R2_2024-06-29_1.csv: Processing failed\n",
      "   - FJ_R3_2024-07-29_1.csv: Processing failed\n",
      "   - AZ_R2_2024-11-22_1.csv: Processing failed\n",
      "   - FJ_R3_2024-06-29_1.csv: Processing failed\n",
      "   - AZ_L3_2024-11-22_1.csv: Processing failed\n",
      "   - FJ_R2_2024-07-15_1.csv: Processing failed\n",
      "   - FU_R2_2024-07-18_1.csv: Processing failed\n",
      "   - K_R3_2025-01-13_1.csv: Processing failed\n",
      "   - K_R2_2025-01-14_1.csv: Processing failed\n",
      "   - AZ_L3_2024-12-16_1.csv: Processing failed\n",
      "   - FJ_R2_2024-06-29_1.csv: Processing failed\n",
      "   - FJ_L3_2024-06-29_1.csv: Processing failed\n",
      "   - FJ_L2_2024-07-29_1.csv: Processing failed\n",
      "   - AZ_R2_2024-12-29_1.csv: Processing failed\n",
      "   - FJ_R2_2024-07-29_1.csv: Processing failed\n",
      "   - K_R3_2025-01-14_1.csv: Processing failed\n",
      "   - FJ_L2_2024-06-29_1.csv: Processing failed\n",
      "   - FS_L2_2024-07-31_1.csv: Processing failed\n",
      "   - FJ_L2_2024-07-15_1.csv: Processing failed\n",
      "   - FJ_L3_2024-07-29_1.csv: Processing failed\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_csv_filename = 'results.csv'\n",
    "sessions = [i for i in  hand_scored_data.keys() if i in gemini_predictions_data.keys()]\n",
    "\n",
    "all_results = utils.process_all_sessions(\n",
    "    sessions=sessions,\n",
    "    hand_scored_data=hand_scored_data,\n",
    "    gemini_predictions_data=gemini_predictions_data,\n",
    "    hand_col='outcome_x',\n",
    "    gemini_col='outcome_y'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "faf1efae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Successfully saved 29 results to 'results.csv'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.save_results(all_results, output_csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c21723d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpi_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
